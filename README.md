# Labs

---

## Лабораторная работе №1

В ходе выполнения лабораторной работы была реализована задача прогнозирования уровня заработной платы с использованием ансамблевых методов машинного обучения. Для решения задачи применялись следующие подходы:

- Целевая переменная (`y`) была прологарифмирована с помощью `np.log1p(y)` для нормализации распределения и снижения влияния выбросов.
- Данные были разделены на обучающую, валидационную и тестовую выборки.
- Был применён препроцессинг: заполнение пропусков медианными значениями и стандартизация признаков.
- Для построения модели использовался ансамбль моделей на основе `StackingRegressor`, включающий:
  - `RandomForestRegressor` с оптимальными гиперпараметрами
  - `GradientBoostingRegressor`
  - `XGBRegressor`
  - `LGBMRegressor`
- Мета-моделью выступала линейная регрессия.

### Полученные метрики:

На тестовой выборке модель показала следующие результаты:

- **MAE (Mean Absolute Error): ~40 000**
- **RMSE: ~70 000**
- **R²: ~0.5**

Такие значения ошибки свидетельствуют о том, что модель ещё не достигла высокой точности предсказания. Ошибка в диапазоне 40 тысяч  является значительной для задачи прогнозирования зарплат.

### Анализ причин низкой точности:

1. **Препроцессинг данных** мог быть недостаточно эффективным:
   - Возможно, не все категориальные признаки были корректно закодированы
   - Отсутствовала работа с выбросами в числовых признаках
   - Не были учтены взаимосвязи между признаками (feature engineering)

2. **Выбор моделей и параметров**:
   - Использование базовых гиперпараметров без глубокого подбора может ограничивать качество
   - Некоторые модели могли недообучаться или переобучаться

3. **Работа с целевой переменной**:
   - Хотя логарифмирование дало положительный эффект, возможно, требуются дополнительные преобразования или борьба с тяжёлыми хвостами
---
## Лабораторная работе №2


В ходе выполнения лабораторной работы была успешно реализована полносвязная нейронная сеть MyMLP на базе NumPy. Были реализованы функции активации, механизм обратного распространения ошибки, поддержка регуляризаций и оптимизаторы. Сеть была протестирована на задачах регрессии и классификации. Результаты сравнивались с реализациями из sklearn, TensorFlow, Keras и PyTorch.


| Модель | Задача | Accuracy / RMSE | Время обучения |
|-------|--------|------------------|----------------|
| **MyMLP (NumPy)** | Регрессия | RMSE = 0.8908 | 37.54 с |
| **MLPRegressor (sklearn)** | Регрессия | RMSE = 0.5766 | 3.06 с |
| **MyMLP (NumPy)** | Классификация | Accuracy = 0.3667 | 0.05 с |
| **MLPClassifier (sklearn)** | Классификация | Accuracy = 0.9333 | 0.05 с |
| **Keras (TensorFlow)** | Классификация | Accuracy = 1.0000 | 7.01 с |
| **PyTorch** | Классификация | Accuracy = 0.9667 | 4.32 с |


### Регрессия (California Housing)

##### MyMLP:
- RMSE: **0.8908**
- Время: **37.54 секунды**

##### sklearn:
- RMSE: **0.5766**
- Время: **3.06 секунды**

- `MyMLP` уступает по качеству и скорости `MLPRegressor` из `sklearn`


### Классификация (Iris)

##### MyMLP:
- Accuracy: **0.3667** (почти случайное угадывание для 3 классов!)
- Время: **0.05 с**

##### sklearn:
- Accuracy: **0.9333**
- Время: **0.05 с**

##### TensorFlow/Keras:
- Accuracy: **1.0000**
- Время: **7.01 с**

##### PyTorch:
- Accuracy: **0.9667**
- Время: **4.32 с**


`MyMLP` обучается хуже чем внешние фреймворки 

### Выводы 

В ходе выполнения лабораторной работы была разработана и протестирована полносвязная нейронная сеть `MyMLP`, реализованная с использованием только библиотеки `NumPy`. Модель была обучена на задачах регрессии (`California Housing`) и многоклассовой классификации (`Iris`).  


Результаты показали, что:

- Реализация `MyMLP` позволяет запустить обучение, но требует доработки для повышения качества.
- Фреймворки `scikit-learn`, `TensorFlow`, `Keras`, `PyTorch` показывают значительно более высокую скорость и качество.

Кастомный класс для полносвязной нейронной сети можно улучшить, если:

- Переправерить обработку batch'ем
- Улучшить инициализацию весов
- Расширить набор поддерживаемых функций активации и лоссов
- Добавить поддержку современных оптимизаторов (Adam, Momentum)

---
## Лабораторная работе №2

В ходе экспериментов были протестированы две стратегии выбора действий — **Softmax** и **UCB** — с подбором гиперпараметров (`T` для Softmax и `c` для UCB). Обе стратегии в конечном итоге достигли **100% win-rate** за 40 000 эпизодов, что говорит об их способности к обучению в данной задаче.

Однако скорость сходимости у стратегий оказалась разной:
- **Softmax**: стабильный win-rate (~100%) был достигнут примерно на **2 000 шаге**.
- **UCB**: аналогичный результат был достигнут значительно позже — около **34 000 шага**.

**Softmax сходится быстрее** в условиях текущей среды `FrozenLake-v0`.


## Softmax

- Позволяет агенту равномерно исследовать действия на ранних этапах, особенно при правильной настройке температуры `T`.
- После начального exploration алгоритм переходит к exploitation наиболее успешных действий, что способствует быстрому обучению.
- Подходит для сред с чётко выраженной "лучшей" политикой, как в случае детерминированного `FrozenLake`.


## UCB (Upper Confidence Bound)

- Делает акцент на исследованиях менее посещаемых состояний и действий, что замедляет сходимость.
- Механизм upper confidence bound полезен в стохастических или сложных средах, где важно избегать преждевременной фокусировки на локальных максимумах.
- В детерминированной среде `FrozenLake` этот механизм оказывается избыточным и требует больше времени для выхода к оптимальной политике.


## Гиперпараметры

### Для **Softmax** ключевым параметром является **температура `T`**:
- При слишком высоких значениях происходит избыточный exploration.
- При слишком низких — алгоритм быстро переходит к exploitation и может застрять на подоптимальной политике.
- В данной задаче низкая температура `T = 0.01` позволила быстро достичь 100% win-rate.

### Для **UCB** важен параметр **`c`**, регулирующий степень exploration:
- Лучшим оказалось значение `c = 1.5`, возможно, диапазон для выбора параметра был не самым удачным.


## Ввыводы

- **Softmax показал лучшие результаты по скорости сходимости** и оказался более подходящим для решения задачи `FrozenLake-v0`.
- **UCB продемонстрировал потенциал, но потребовал гораздо больше времени для обучения**, что делает его менее эффективным в простых и детерминированных средах.

---
