# Labs

---

## Лабораторная работе №1

В ходе выполнения лабораторной работы была реализована задача прогнозирования уровня заработной платы с использованием ансамблевых методов машинного обучения. Для решения задачи применялись следующие подходы:

- Целевая переменная (`y`) была прологарифмирована с помощью `np.log1p(y)` для нормализации распределения и снижения влияния выбросов.
- Данные были разделены на обучающую, валидационную и тестовую выборки.
- Был применён препроцессинг: заполнение пропусков медианными значениями и стандартизация признаков.
- Для построения модели использовался ансамбль моделей на основе `StackingRegressor`, включающий:
  - `RandomForestRegressor` с оптимальными гиперпараметрами
  - `GradientBoostingRegressor`
  - `XGBRegressor`
  - `LGBMRegressor`
- Мета-моделью выступала линейная регрессия.

### Полученные метрики:

На тестовой выборке модель показала следующие результаты:

- **MAE (Mean Absolute Error): ~40 000**
- **RMSE: ~70 000**
- **R²: ~0.5**

Такие значения ошибки свидетельствуют о том, что модель ещё не достигла высокой точности предсказания. Ошибка в диапазоне 40 тысяч  является значительной для задачи прогнозирования зарплат.

### Анализ причин низкой точности:

1. **Препроцессинг данных** мог быть недостаточно эффективным:
   - Возможно, не все категориальные признаки были корректно закодированы
   - Отсутствовала работа с выбросами в числовых признаках
   - Не были учтены взаимосвязи между признаками (feature engineering)

2. **Выбор моделей и параметров**:
   - Использование базовых гиперпараметров без глубокого подбора может ограничивать качество
   - Некоторые модели могли недообучаться или переобучаться

3. **Работа с целевой переменной**:
   - Хотя логарифмирование дало положительный эффект, возможно, требуются дополнительные преобразования или борьба с тяжёлыми хвостами
---
## Лабораторная работе №2


В ходе выполнения лабораторной работы была успешно реализована полносвязная нейронная сеть MyMLP на базе NumPy. Были реализованы функции активации, механизм обратного распространения ошибки, поддержка регуляризаций и оптимизаторы. Сеть была протестирована на задачах регрессии и классификации. Результаты сравнивались с реализациями из sklearn, TensorFlow, Keras и PyTorch.


| Модель | Задача | Accuracy / RMSE | Время обучения |
|-------|--------|------------------|----------------|
| **MyMLP (NumPy)** | Регрессия | RMSE = 0.8908 | 37.54 с |
| **MLPRegressor (sklearn)** | Регрессия | RMSE = 0.5766 | 3.06 с |
| **MyMLP (NumPy)** | Классификация | Accuracy = 0.3667 | 0.05 с |
| **MLPClassifier (sklearn)** | Классификация | Accuracy = 0.9333 | 0.05 с |
| **Keras (TensorFlow)** | Классификация | Accuracy = 1.0000 | 7.01 с |
| **PyTorch** | Классификация | Accuracy = 0.9667 | 4.32 с |


### Регрессия (California Housing)

##### MyMLP:
- RMSE: **0.8908**
- Время: **37.54 секунды**

##### sklearn:
- RMSE: **0.5766**
- Время: **3.06 секунды**

- `MyMLP` уступает по качеству и скорости `MLPRegressor` из `sklearn`


### Классификация (Iris)

##### MyMLP:
- Accuracy: **0.3667** (почти случайное угадывание для 3 классов!)
- Время: **0.05 с**

##### sklearn:
- Accuracy: **0.9333**
- Время: **0.05 с**

##### TensorFlow/Keras:
- Accuracy: **1.0000**
- Время: **7.01 с**

##### PyTorch:
- Accuracy: **0.9667**
- Время: **4.32 с**


`MyMLP` обучается хуже чем внешние фреймворки 

### Выводы 

В ходе выполнения лабораторной работы была разработана и протестирована полносвязная нейронная сеть `MyMLP`, реализованная с использованием только библиотеки `NumPy`. Модель была обучена на задачах регрессии (`California Housing`) и многоклассовой классификации (`Iris`).  


Результаты показали, что:

- Реализация `MyMLP` позволяет запустить обучение, но требует доработки для повышения качества.
- Фреймворки `scikit-learn`, `TensorFlow`, `Keras`, `PyTorch` показывают значительно более высокую скорость и качество.

Кастомный класс для полносвязной нейронной сети можно улучшить, если:

- Переправерить обработку batch'ем
- Улучшить инициализацию весов
- Расширить набор поддерживаемых функций активации и лоссов
- Добавить поддержку современных оптимизаторов (Adam, Momentum)

---
